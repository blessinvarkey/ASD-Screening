# Blessin Varkey

1. **About Me**
2. [Published Research](https://blessinvarkey.github.io/research)
3. Projects
  - Accessibility Projects
  - Computer Vision Project 
  - Machine Learning Project
4. Personal Projects
  - [AstroPy Blog](https://blessinvarkey.github.io/astropy)

## Kinect Sensor

![alt image](Architecture-of-Microsoft-Kinect-sensor.png)
The motion sensing device, Microsoft Kinect, enables users of all ages to interact through gestures. Kinect has been used in a wide rage of areas including healthcare, education,  performing arts, robotics, sign language recognition, retail services, workplace safety training, as well as 3D reconstructions[1](https://www.researchgate.net/publication/277637546_A_Survey_of_Applications_and_Human_Motion_Recognition_with_Microsoft_Kinect). Lets now look at the three 
###  1. Optical Subsystem 
  - The Optical Subsystem consists of a Depth Projector, Depth Sensor and a RGB Camera. 
      - The Depth Projector (infrared projector) & Depth Sensor (monochrome CMOS sensor) work together to identify patterns in the room - like distance of the sensor from the hand and from the face, regardless of the lighting conditions. 
      - The RGB Camera or the Color VGA video camera helps in detecting RGB colors, facial recognition, movements, taking pictures.
 
###  2. Motor Subsystem  
  - The motor subsystem is designed to detect and adjust location, space, height in real time. 
 
###  3. Audio Subsystem
  - The audio subsystem consists of four microphones and an audio processor to isolate the voices and cancel the noise in the room. 

Image [source](file:///C:/Users/user/Downloads/Hybrid_Motion_Planning_Method_for_Autonomous_Robot.pdf)
